{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.neighbors import NearestCentroid"
      ],
      "metadata": {
        "id": "yh4oxHPcG2CO"
      },
      "id": "yh4oxHPcG2CO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fca3a9ae",
      "metadata": {
        "id": "fca3a9ae"
      },
      "outputs": [],
      "source": [
        "categories=['sci.med','sci.space','sci.electronics']\n",
        "news_train=fetch_20newsgroups(subset='train',categories=categories,shuffle=True)\n",
        "news_test=fetch_20newsgroups(subset='test',categories=categories,shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f981c9a3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f981c9a3",
        "outputId": "aaca596a-097a-43e5-8068-9dd7be592e68"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1778, 31201)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count_vect=CountVectorizer()\n",
        "X_train_tf=count_vect.fit_transform(news_train.data)\n",
        "X_train_tf.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "803d86a4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "803d86a4",
        "outputId": "8fc86e49-369c-47ab-c378-a0a6c178b2ec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1778, 31201)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "tfidf_transformer=TfidfTransformer()\n",
        "X_train_tfidf=tfidf_transformer.fit_transform(X_train_tf)\n",
        "X_train_tfidf.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84df8bd4",
      "metadata": {
        "id": "84df8bd4"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "clf=MultinomialNB().fit(X_train_tfidf,news_train.target)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63e46ca5",
      "metadata": {
        "id": "63e46ca5"
      },
      "outputs": [],
      "source": [
        "X_test_tf=count_vect.transform(news_test.data)\n",
        "X_test_tfidf=tfidf_transformer.transform(X_test_tf)\n",
        "predicted=clf.predict(X_test_tfidf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbfb8cd7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbfb8cd7",
        "outputId": "8d816ad3-35c9-4929-996e-2ff00e584a36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy 0.9357565511411665\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "sci.electronics       0.95      0.90      0.92       393\n",
            "        sci.med       0.94      0.94      0.94       396\n",
            "      sci.space       0.92      0.97      0.94       394\n",
            "\n",
            "       accuracy                           0.94      1183\n",
            "      macro avg       0.94      0.94      0.94      1183\n",
            "   weighted avg       0.94      0.94      0.94      1183\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, array([[353,  14,  26],\n",
              "        [ 17, 371,   8],\n",
              "        [  3,   8, 383]]))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "print(\"Accuracy\",accuracy_score(news_test.target,predicted))\n",
        "print(metrics.classification_report(news_test.target,predicted,target_names=news_test.target_names)),metrics.confusion_matrix(news_test.target,predicted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b80a4c1d",
        "outputId": "c718b159-3182-4872-fab2-6eabc5a22f36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['sci.electronics', 'sci.med', 'sci.space']\n",
            "From: landis@stsci.edu (Robert Landis,S202,,)\n",
            "Subject: Re: Space Debris\n",
            "Reply-To: landis@stsci.edu\n",
            "sci.space\n",
            "sci.space\n",
            "sci.electronics\n",
            "sci.med\n",
            "sci.med\n",
            "sci.space\n",
            "sci.space\n",
            "sci.med\n",
            "sci.med\n",
            "sci.space\n",
            "sci.med\n",
            "'I have a Harley Davidson and Yamaha.' => sci.med\n",
            "'I have a GTX 1050 GPU' => sci.med\n",
            "Accuracy 0.8571428571428571\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "sci.electronics       0.84      0.80      0.82       393\n",
            "        sci.med       0.85      0.84      0.85       396\n",
            "      sci.space       0.88      0.93      0.90       394\n",
            "\n",
            "       accuracy                           0.86      1183\n",
            "      macro avg       0.86      0.86      0.86      1183\n",
            "   weighted avg       0.86      0.86      0.86      1183\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[313,  47,  33],\n",
              "       [ 44, 334,  18],\n",
              "       [ 14,  13, 367]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# We defined the categories which we want to classify\n",
        "categories = ['sci.med','sci.space','sci.electronics']\n",
        "\n",
        "# sklearn provides us with subset data for training and testing\n",
        "train_data = fetch_20newsgroups(subset='train',categories=categories, shuffle=True)\n",
        "\n",
        "print(train_data.target_names)\n",
        "\n",
        "print(\"\\n\".join(train_data.data[0].split(\"\\n\")[:3]))\n",
        "print(train_data.target_names[train_data.target[0]])\n",
        "\n",
        "# Let's look at categories of our first ten training data\n",
        "for t in train_data.target[:10]:\n",
        "    print(train_data.target_names[t])\n",
        "# Builds a dictionary of features and transforms documents to feature vectors and convert our text documents to a\n",
        "# matrix of token counts (CountVectorizer)\n",
        "count_vect = CountVectorizer()\n",
        "X_train_counts = count_vect.fit_transform(train_data.data)\n",
        "\n",
        "# transform a count matrix to a normalized tf-idf representation (tf-idf transformer)\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "# training our classifier ; train_data.target will be having numbers assigned for each category in train data\n",
        "clf = knn.fit(X_train_tfidf, train_data.target)\n",
        "\n",
        "# Input Data to predict their classes of the given categories\n",
        "docs_new = ['I have a Harley Davidson and Yamaha.', 'I have a GTX 1050 GPU']\n",
        "# building up feature vector of our input\n",
        "X_new_counts = count_vect.transform(docs_new)\n",
        "# We call transform instead of fit_transform because it's already been fit\n",
        "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
        "# predicting the category of our input text: Will give out number for category\n",
        "predicted = clf.predict(X_new_tfidf)\n",
        "\n",
        "for doc, category in zip(docs_new, predicted):\n",
        "    print('%r => %s' % (doc, train_data.target_names[category]))\n",
        "# We can use Pipeline to add vectorizer -> transformer -> classifier all in a one compound classifier\n",
        "text_clf = Pipeline([\n",
        "    ('vect', CountVectorizer()),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('clf', knn),\n",
        "])\n",
        "# Fitting our train data to the pipeline\n",
        "text_clf.fit(train_data.data, train_data.target)\n",
        "\n",
        "# Test data \n",
        "test_data = fetch_20newsgroups(subset='test',categories=categories, shuffle=True)\n",
        "docs_test = test_data.data\n",
        "# Predicting our test data\n",
        "predicted = text_clf.predict(docs_test)\n",
        "\n",
        "print(\"Accuracy\",accuracy_score(test_data.target,predicted))\n",
        "print(metrics.classification_report(test_data.target,predicted,target_names=test_data.target_names)),\n",
        "metrics.confusion_matrix(test_data.target,predicted)\n"
      ],
      "id": "b80a4c1d"
    },
    {
      "cell_type": "code",
      "source": [
        "categories = ['sci.med','sci.space','sci.electronics']\n",
        "newsgroups_train=fetch_20newsgroups(subset='train',categories=categories,shuffle=True)\n",
        "newsgroups_test=fetch_20newsgroups(subset='test',categories=categories,shuffle=True)\n",
        "#newsgroups_train = fetch_20newsgroups(subset='train')\n",
        "#newsgroups_test = fetch_20newsgroups(subset='test')\n",
        "X_train = newsgroups_train.data\n",
        "X_test = newsgroups_test.data\n",
        "y_train = newsgroups_train.target\n",
        "y_test = newsgroups_test.target\n",
        "\n",
        "text_clf = Pipeline([('vect', CountVectorizer()),\n",
        "                     ('tfidf', TfidfTransformer()),\n",
        "                     ('clf', NearestCentroid()),\n",
        "                     ])\n",
        "\n",
        "text_clf.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "predicted = text_clf.predict(X_test)\n",
        "print(\"Accuracy\",accuracy_score(test_data.target,predicted))\n",
        "print(metrics.classification_report(test_data.target,predicted,target_names=test_data.target_names)),\n",
        "metrics.confusion_matrix(test_data.target,predicted)"
      ],
      "metadata": {
        "id": "XE13bl7HGwn4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03452d3e-96b4-48b8-c131-cc1f7f0aa275"
      },
      "id": "XE13bl7HGwn4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy 0.801352493660186\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "sci.electronics       0.66      0.91      0.76       393\n",
            "        sci.med       0.88      0.63      0.74       396\n",
            "      sci.space       0.96      0.86      0.91       394\n",
            "\n",
            "       accuracy                           0.80      1183\n",
            "      macro avg       0.83      0.80      0.80      1183\n",
            "   weighted avg       0.83      0.80      0.80      1183\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[359,  24,  10],\n",
              "       [142, 250,   4],\n",
              "       [ 45,  10, 339]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "woNJELqUGAtd"
      },
      "id": "woNJELqUGAtd",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "naive_bayes.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}